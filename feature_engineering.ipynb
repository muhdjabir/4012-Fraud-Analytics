{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep = ',')\n",
    "validate = pd.read_csv('validate.csv', sep = ',')\n",
    "test = pd.read_csv('test.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350000\n",
      "50000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(validate))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelly/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision over training dataset: 0.5312\n",
      "Precision over validation dataset: 0.5320\n",
      "Precision over test dataset: 0.5124\n",
      "Recall over training dataset: 0.9857\n",
      "Recall over validation dataset: 0.9823\n",
      "Recall over test dataset: 0.9840\n",
      "F1 score over training dataset: 0.6904\n",
      "F1 score over validation dataset: 0.6902\n",
      "F1 score over test dataset: 0.6739\n",
      "[[91163  4273]\n",
      " [   73  4491]]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [col for col in train.columns if (col != 'fraud')]\n",
    "target_col = ['fraud']\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[target_col].copy()\n",
    "X_validate = validate[feature_cols].copy()\n",
    "y_validate = validate[target_col].copy()\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[target_col].copy()\n",
    "\n",
    "LogR = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000) # for imbalanced learning\n",
    "LogR.fit(X_train, y_train)\n",
    "\n",
    "# Calculate precision and recall for the training dataset\n",
    "precision_train = precision_score(y_train, LogR.predict(X_train))\n",
    "recall_train = recall_score(y_train, LogR.predict(X_train))\n",
    "\n",
    "# Calculate precision and recall for the validation dataset\n",
    "precision_validate = precision_score(y_validate, LogR.predict(X_validate))\n",
    "recall_validate = recall_score(y_validate, LogR.predict(X_validate))\n",
    "\n",
    "# Calculate precision and recall for the test dataset\n",
    "precision_test = precision_score(y_test, LogR.predict(X_test))\n",
    "recall_test = recall_score(y_test, LogR.predict(X_test))\n",
    "\n",
    "print('Precision over training dataset: {:0.4f}'.format(precision_train))\n",
    "print('Precision over validation dataset: {:0.4f}'.format(precision_validate))\n",
    "print('Precision over test dataset: {:0.4f}'.format(precision_test))\n",
    "print('Recall over training dataset: {:0.4f}'.format(recall_train))\n",
    "print('Recall over validation dataset: {:0.4f}'.format(recall_validate))\n",
    "print('Recall over test dataset: {:0.4f}'.format(recall_test))\n",
    "print('F1 score over training dataset: {:0.4f}'.format(f1_score(y_train, LogR.predict(X_train))))\n",
    "print('F1 score over validation dataset: {:0.4f}'.format(f1_score(y_validate, LogR.predict(X_validate))))\n",
    "print('F1 score over test dataset: {:0.4f}'.format(f1_score(y_test, LogR.predict(X_test))))\n",
    "temp = LogR.predict(X_test)\n",
    "c_mat = confusion_matrix(y_test, temp)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features that might be useful\n",
    "- attempted_scan: attempted (1) or did not attempt (0)\n",
    "- made_modification: made modification (1) or did not make any modification (0)\n",
    "- no. of items scanned = totalScanTimeInSeconds * scannedLineItemsPerSecond\n",
    "- avg value of each item = grandTotal / no. of items scanned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['attempted_scan'] = np.where(train['scansWithoutRegistration'] > 0, 1, 0)\n",
    "validate['attempted_scan'] = np.where(validate['scansWithoutRegistration'] > 0, 1, 0)\n",
    "test['attempted_scan'] = np.where(test['scansWithoutRegistration'] > 0, 1, 0)\n",
    "\n",
    "train['made_modification'] = np.where(train['quantityModifications'] > 0, 1, 0)\n",
    "validate['made_modification'] = np.where(validate['quantityModifications'] > 0, 1, 0)\n",
    "test['made_modification'] = np.where(test['quantityModifications'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['total_items_scanned'] = train['totalScanTimeInSeconds'] * train['scannedLineItemsPerSecond']\n",
    "validate['total_items_scanned'] = validate['totalScanTimeInSeconds'] * validate['scannedLineItemsPerSecond']\n",
    "test['total_items_scanned'] = test['totalScanTimeInSeconds'] * test['scannedLineItemsPerSecond']\n",
    "\n",
    "train['value_per_item'] = train['grandTotal'] / train['total_items_scanned']\n",
    "validate['value_per_item'] = validate['grandTotal'] / validate['total_items_scanned']\n",
    "test['value_per_item'] = test['grandTotal'] / test['total_items_scanned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression before anything**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression before scaling and binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train.columns if (col != 'fraud')]\n",
    "target_col = ['fraud']\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[target_col].copy()\n",
    "X_validate = validate[feature_cols].copy()\n",
    "y_validate = validate[target_col].copy()\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelly/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kelly/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision over training dataset: 0.7232\n",
      "Precision over validation dataset: 0.7284\n",
      "Precision over test dataset: 0.7098\n",
      "Recall over training dataset: 0.9941\n",
      "Recall over validation dataset: 0.9942\n",
      "Recall over test dataset: 0.9934\n",
      "F1 score over training dataset: 0.8373\n",
      "F1 score over validation dataset: 0.8408\n",
      "F1 score over test dataset: 0.8280\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [col for col in train.columns if (col != 'fraud')]\n",
    "target_col = ['fraud']\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[target_col].copy()\n",
    "X_validate = validate[feature_cols].copy()\n",
    "y_validate = validate[target_col].copy()\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[target_col].copy()\n",
    "\n",
    "LogR = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000) # for imbalanced learning\n",
    "LogR.fit(X_train, y_train)\n",
    "\n",
    "# Calculate precision and recall for the training dataset\n",
    "precision_train = precision_score(y_train, LogR.predict(X_train))\n",
    "recall_train = recall_score(y_train, LogR.predict(X_train))\n",
    "\n",
    "# Calculate precision and recall for the validation dataset\n",
    "precision_validate = precision_score(y_validate, LogR.predict(X_validate))\n",
    "recall_validate = recall_score(y_validate, LogR.predict(X_validate))\n",
    "\n",
    "# Calculate precision and recall for the test dataset\n",
    "precision_test = precision_score(y_test, LogR.predict(X_test))\n",
    "recall_test = recall_score(y_test, LogR.predict(X_test))\n",
    "\n",
    "print('Precision over training dataset: {:0.4f}'.format(precision_train))\n",
    "print('Precision over validation dataset: {:0.4f}'.format(precision_validate))\n",
    "print('Precision over test dataset: {:0.4f}'.format(precision_test))\n",
    "print('Recall over training dataset: {:0.4f}'.format(recall_train))\n",
    "print('Recall over validation dataset: {:0.4f}'.format(recall_validate))\n",
    "print('Recall over test dataset: {:0.4f}'.format(recall_test))\n",
    "print('F1 score over training dataset: {:0.4f}'.format(f1_score(y_train, LogR.predict(X_train))))\n",
    "print('F1 score over validation dataset: {:0.4f}'.format(f1_score(y_validate, LogR.predict(X_validate))))\n",
    "print('F1 score over test dataset: {:0.4f}'.format(f1_score(y_test, LogR.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make trust levels as factors\n",
    "- don't need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log scaling for scannedLineItemsPerSecond, lineItemVoidsPerPosition, total_items_scanned, totalScanTimeInSeconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = train.copy(deep=True)\n",
    "test_log = test.copy(deep=True)\n",
    "validate_log = validate.copy(deep=True)\n",
    "\n",
    "train_log[['scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']] = np.log(train_log[['scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']] + 1e-10)\n",
    "test_log[['scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']] = np.log(test_log[['scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']] + 1e-10)\n",
    "validate_log[['scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']] = np.log(validate_log[['scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']] + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling all continous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [col for col in train.columns if \n",
    "            (col != 'fraud') and (col != 'attempted_scan') and (col != 'made_modification') and (col != 'trustLevel') and\n",
    "            (col != 'scannedLineItemsPerSecond') and (col != 'valuePerSecond') and (col != 'lineItemVoidsPerPosition')]\n",
    "new_col_names = [f'scaled_{col}' for col in all_cols]\n",
    "\n",
    "scaler = StandardScaler().fit(train[all_cols])\n",
    "train[new_col_names] = scaler.transform(train[all_cols])\n",
    "validate[new_col_names] = scaler.transform(validate[all_cols])\n",
    "test[new_col_names] = scaler.transform(test[all_cols])\n",
    "\n",
    "# drop original columns\n",
    "train = train.drop(columns = all_cols)\n",
    "validate = validate.drop(columns = all_cols)\n",
    "test = test.drop(columns = all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "      <th>attempted_scan</th>\n",
       "      <th>made_modification</th>\n",
       "      <th>scaled_totalScanTimeInSeconds</th>\n",
       "      <th>scaled_grandTotal</th>\n",
       "      <th>scaled_lineItemVoids</th>\n",
       "      <th>scaled_scansWithoutRegistration</th>\n",
       "      <th>scaled_quantityModifications</th>\n",
       "      <th>scaled_total_items_scanned</th>\n",
       "      <th>scaled_value_per_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.012834</td>\n",
       "      <td>0.046995</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035712</td>\n",
       "      <td>-0.209627</td>\n",
       "      <td>-1.014426</td>\n",
       "      <td>1.266427</td>\n",
       "      <td>1.464869</td>\n",
       "      <td>-0.404018</td>\n",
       "      <td>-0.258825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.078887</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.832083</td>\n",
       "      <td>-0.430823</td>\n",
       "      <td>1.305782</td>\n",
       "      <td>0.317330</td>\n",
       "      <td>-0.877377</td>\n",
       "      <td>-1.327436</td>\n",
       "      <td>0.231571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.029093</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.919052</td>\n",
       "      <td>-1.297610</td>\n",
       "      <td>-0.434374</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.293746</td>\n",
       "      <td>-0.981154</td>\n",
       "      <td>-0.419371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.141328</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.248020</td>\n",
       "      <td>-0.478247</td>\n",
       "      <td>-0.144348</td>\n",
       "      <td>-0.948134</td>\n",
       "      <td>0.879307</td>\n",
       "      <td>-0.981154</td>\n",
       "      <td>-0.129764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.017785</td>\n",
       "      <td>0.078868</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606680</td>\n",
       "      <td>1.646488</td>\n",
       "      <td>0.725730</td>\n",
       "      <td>0.950061</td>\n",
       "      <td>0.293746</td>\n",
       "      <td>0.750256</td>\n",
       "      <td>-0.192631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  scannedLineItemsPerSecond  valuePerSecond  \\\n",
       "0           2                   0.012834        0.046995   \n",
       "1           4                   0.008403        0.078887   \n",
       "2           5                   0.016279        0.029093   \n",
       "3           1                   0.027344        0.141328   \n",
       "4           2                   0.017785        0.078868   \n",
       "\n",
       "   lineItemVoidsPerPosition  fraud  attempted_scan  made_modification  \\\n",
       "0                  0.166667      0               1                  1   \n",
       "1                  2.500000      0               1                  1   \n",
       "2                  0.571429      0               1                  1   \n",
       "3                  0.714286      0               1                  1   \n",
       "4                  0.363636      0               1                  1   \n",
       "\n",
       "   scaled_totalScanTimeInSeconds  scaled_grandTotal  scaled_lineItemVoids  \\\n",
       "0                       0.035712          -0.209627             -1.014426   \n",
       "1                      -0.832083          -0.430823              1.305782   \n",
       "2                      -0.919052          -1.297610             -0.434374   \n",
       "3                      -1.248020          -0.478247             -0.144348   \n",
       "4                       0.606680           1.646488              0.725730   \n",
       "\n",
       "   scaled_scansWithoutRegistration  scaled_quantityModifications  \\\n",
       "0                         1.266427                      1.464869   \n",
       "1                         0.317330                     -0.877377   \n",
       "2                         0.000964                      0.293746   \n",
       "3                        -0.948134                      0.879307   \n",
       "4                         0.950061                      0.293746   \n",
       "\n",
       "   scaled_total_items_scanned  scaled_value_per_item  \n",
       "0                   -0.404018              -0.258825  \n",
       "1                   -1.327436               0.231571  \n",
       "2                   -0.981154              -0.419371  \n",
       "3                   -0.981154              -0.129764  \n",
       "4                    0.750256              -0.192631  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train.columns if (col != 'fraud')]\n",
    "target_col = ['fraud']\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[target_col].copy()\n",
    "X_validate = validate[feature_cols].copy()\n",
    "y_validate = validate[target_col].copy()\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelly/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision over training dataset: 0.7347\n",
      "Precision over validation dataset: 0.7353\n",
      "Precision over test dataset: 0.7216\n",
      "Recall over training dataset: 0.9946\n",
      "Recall over validation dataset: 0.9963\n",
      "Recall over test dataset: 0.9947\n",
      "F1 score over training dataset: 0.8451\n",
      "F1 score over validation dataset: 0.8461\n",
      "F1 score over test dataset: 0.8364\n"
     ]
    }
   ],
   "source": [
    "LogR = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000) # for imbalanced learning\n",
    "LogR.fit(X_train, y_train)\n",
    "\n",
    "# Calculate precision and recall for the training dataset\n",
    "precision_train = precision_score(y_train, LogR.predict(X_train))\n",
    "recall_train = recall_score(y_train, LogR.predict(X_train))\n",
    "\n",
    "# Calculate precision and recall for the validation dataset\n",
    "precision_validate = precision_score(y_validate, LogR.predict(X_validate))\n",
    "recall_validate = recall_score(y_validate, LogR.predict(X_validate))\n",
    "\n",
    "# Calculate precision and recall for the test dataset\n",
    "precision_test = precision_score(y_test, LogR.predict(X_test))\n",
    "recall_test = recall_score(y_test, LogR.predict(X_test))\n",
    "\n",
    "print('Precision over training dataset: {:0.4f}'.format(precision_train))\n",
    "print('Precision over validation dataset: {:0.4f}'.format(precision_validate))\n",
    "print('Precision over test dataset: {:0.4f}'.format(precision_test))\n",
    "print('Recall over training dataset: {:0.4f}'.format(recall_train))\n",
    "print('Recall over validation dataset: {:0.4f}'.format(recall_validate))\n",
    "print('Recall over test dataset: {:0.4f}'.format(recall_test))\n",
    "print('F1 score over training dataset: {:0.4f}'.format(f1_score(y_train, LogR.predict(X_train))))\n",
    "print('F1 score over validation dataset: {:0.4f}'.format(f1_score(y_validate, LogR.predict(X_validate))))\n",
    "print('F1 score over test dataset: {:0.4f}'.format(f1_score(y_test, LogR.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove some features that are highly correlated to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated variable pairs:\n",
      "valuePerSecond and scannedLineItemsPerSecond have a correlation of 0.7472137111808428\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have already calculated the correlation matrix\n",
    "correlation_matrix_train = train.corr()\n",
    "\n",
    "# Set a threshold for high correlation\n",
    "threshold = 0.7  # You can adjust this threshold as needed\n",
    "\n",
    "# Find highly correlated pairs of variables\n",
    "highly_correlated_pairs = set()\n",
    "for i in range(len(correlation_matrix_train.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix_train.iloc[i, j]) > threshold:\n",
    "            col1 = correlation_matrix_train.columns[i]\n",
    "            col2 = correlation_matrix_train.columns[j]\n",
    "            highly_correlated_pairs.add((col1, col2))\n",
    "\n",
    "# Print the highly correlated variable pairs\n",
    "print(\"Highly correlated variable pairs:\")\n",
    "for pair in highly_correlated_pairs:\n",
    "    print(f\"{pair[0]} and {pair[1]} have a correlation of {correlation_matrix_train.loc[pair[0], pair[1]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove those highly correlated\n",
    "- scannedLineItemsPerSecond\n",
    "- totalScanTimeInSeconds\n",
    "- lineItemVoidsPerPosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train.columns if (col != 'fraud') and (col != 'scaled_quantityModifications')\n",
    "                and (col != 'scaled_value_per_item') and (col != 'valuePerSecond')]\n",
    "target_col = ['fraud']\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[target_col].copy()\n",
    "X_validate = validate[feature_cols].copy()\n",
    "y_validate = validate[target_col].copy()\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trustLevel', 'scannedLineItemsPerSecond', 'lineItemVoidsPerPosition', 'attempted_scan', 'made_modification', 'scaled_totalScanTimeInSeconds', 'scaled_grandTotal', 'scaled_lineItemVoids', 'scaled_scansWithoutRegistration', 'scaled_total_items_scanned']\n"
     ]
    }
   ],
   "source": [
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelly/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision over training dataset: 0.7348\n",
      "Precision over validation dataset: 0.7344\n",
      "Precision over test dataset: 0.7212\n",
      "Recall over training dataset: 0.9946\n",
      "Recall over validation dataset: 0.9955\n",
      "Recall over test dataset: 0.9947\n",
      "F1 score over training dataset: 0.8452\n",
      "F1 score over validation dataset: 0.8453\n",
      "F1 score over test dataset: 0.8362\n"
     ]
    }
   ],
   "source": [
    "LogR = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000) # for imbalanced learning\n",
    "LogR.fit(X_train, y_train)\n",
    "\n",
    "# Calculate precision and recall for the training dataset\n",
    "precision_train = precision_score(y_train, LogR.predict(X_train))\n",
    "recall_train = recall_score(y_train, LogR.predict(X_train))\n",
    "\n",
    "# Calculate precision and recall for the validation dataset\n",
    "precision_validate = precision_score(y_validate, LogR.predict(X_validate))\n",
    "recall_validate = recall_score(y_validate, LogR.predict(X_validate))\n",
    "\n",
    "# Calculate precision and recall for the test dataset\n",
    "precision_test = precision_score(y_test, LogR.predict(X_test))\n",
    "recall_test = recall_score(y_test, LogR.predict(X_test))\n",
    "\n",
    "print('Precision over training dataset: {:0.4f}'.format(precision_train))\n",
    "print('Precision over validation dataset: {:0.4f}'.format(precision_validate))\n",
    "print('Precision over test dataset: {:0.4f}'.format(precision_test))\n",
    "print('Recall over training dataset: {:0.4f}'.format(recall_train))\n",
    "print('Recall over validation dataset: {:0.4f}'.format(recall_validate))\n",
    "print('Recall over test dataset: {:0.4f}'.format(recall_test))\n",
    "print('F1 score over training dataset: {:0.4f}'.format(f1_score(y_train, LogR.predict(X_train))))\n",
    "print('F1 score over validation dataset: {:0.4f}'.format(f1_score(y_validate, LogR.predict(X_validate))))\n",
    "print('F1 score over test dataset: {:0.4f}'.format(f1_score(y_test, LogR.predict(X_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
