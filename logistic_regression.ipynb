{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350000\n",
      "100000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', sep = ',')\n",
    "validate = pd.read_csv('validate.csv', sep = ',')\n",
    "test = pd.read_csv('test.csv', sep = ',')\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(validate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Run Logistic Regression on Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision over training dataset: 0.5312\n",
      "Precision over validation dataset: 0.5320\n",
      "Precision over test dataset: 0.5124\n",
      "Recall over training dataset: 0.9857\n",
      "Recall over validation dataset: 0.9823\n",
      "Recall over test dataset: 0.9840\n",
      "F1 score over training dataset: 0.6904\n",
      "F1 score over validation dataset: 0.6902\n",
      "F1 score over test dataset: 0.6739\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [col for col in train.columns if (col != 'fraud')]\n",
    "target_col = ['fraud']\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[target_col].copy()\n",
    "X_validate = validate[feature_cols].copy()\n",
    "y_validate = validate[target_col].copy()\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[target_col].copy()\n",
    "\n",
    "LogR = LogisticRegression(random_state=42, class_weight='balanced', max_iter=2000) # for imbalanced learning\n",
    "LogR.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Calculate precision, recall and f1-score for the training dataset\n",
    "precision_train = precision_score(y_train, LogR.predict(X_train))\n",
    "recall_train = recall_score(y_train, LogR.predict(X_train))\n",
    "f1_score_train = f1_score(y_train, LogR.predict(X_train))\n",
    "\n",
    "# Calculate precision, recall and f1-score for the validation dataset\n",
    "precision_validate = precision_score(y_validate, LogR.predict(X_validate))\n",
    "recall_validate = recall_score(y_validate, LogR.predict(X_validate))\n",
    "f1_score_validate = f1_score(y_validate, LogR.predict(X_validate))\n",
    "\n",
    "# Calculate precision, recall and f1-score for the test dataset\n",
    "precision_test = precision_score(y_test, LogR.predict(X_test))\n",
    "recall_test = recall_score(y_test, LogR.predict(X_test))\n",
    "f1_score_test = f1_score(y_test, LogR.predict(X_test))\n",
    "\n",
    "print('Precision over training dataset: {:0.4f}'.format(precision_train))\n",
    "print('Precision over validation dataset: {:0.4f}'.format(precision_validate))\n",
    "print('Precision over test dataset: {:0.4f}'.format(precision_test))\n",
    "print('Recall over training dataset: {:0.4f}'.format(recall_train))\n",
    "print('Recall over validation dataset: {:0.4f}'.format(recall_validate))\n",
    "print('Recall over test dataset: {:0.4f}'.format(recall_test))\n",
    "print('F1 score over training dataset: {:0.4f}'.format(f1_score_train))\n",
    "print('F1 score over validation dataset: {:0.4f}'.format(f1_score_validate))\n",
    "print('F1 score over test dataset: {:0.4f}'.format(f1_score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>create new feature `totalItems`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['totalItems'] = train['totalScanTimeInSeconds'] * train['scannedLineItemsPerSecond']\n",
    "validate['totalItems'] = validate['totalScanTimeInSeconds'] * validate['scannedLineItemsPerSecond']\n",
    "test['totalItems'] = test['totalScanTimeInSeconds'] * test['scannedLineItemsPerSecond']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Check for skewness of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trustLevel                   -0.000681\n",
      "totalScanTimeInSeconds       -0.000135\n",
      "grandTotal                   -0.002165\n",
      "lineItemVoids                 0.001811\n",
      "scansWithoutRegistration      0.001743\n",
      "quantityModifications         0.000359\n",
      "scannedLineItemsPerSecond    31.774127\n",
      "valuePerSecond               31.442346\n",
      "lineItemVoidsPerPosition      4.535840\n",
      "totalItems                   -0.000936\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check skewness of data\n",
    "feature_cols = [col for col in train.columns if (col != 'fraud')]\n",
    "target_col = ['fraud']\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[target_col].copy()\n",
    "X_validate = validate[feature_cols].copy()\n",
    "y_validate = validate[target_col].copy()\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[target_col].copy()\n",
    "\n",
    "print(X_train.skew(axis = 0, skipna = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, we can see that `scannedLineItemsPerSecond`, `valuePerSecond`, and `lineItemVoidsPerPosition` are positively skewed. We can then do log transformation on these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[:, 'scannedLineItemsPerSecond'] = np.log(X_train.loc[:, 'scannedLineItemsPerSecond'] + 1)\n",
    "X_train.loc[:, 'valuePerSecond'] = np.log(X_train.loc[:, 'valuePerSecond'] + 1)\n",
    "X_train.loc[:, 'lineItemVoidsPerPosition'] = np.log(X_train.loc[:, 'lineItemVoidsPerPosition'] + 1)\n",
    "\n",
    "X_validate.loc[:, 'scannedLineItemsPerSecond'] = np.log(X_validate.loc[:, 'scannedLineItemsPerSecond'] + 1)\n",
    "X_validate.loc[:, 'valuePerSecond'] = np.log(X_validate.loc[:, 'valuePerSecond'] + 1)\n",
    "X_validate.loc[:, 'lineItemVoidsPerPosition'] = np.log(X_validate.loc[:, 'lineItemVoidsPerPosition'] + 1)\n",
    "\n",
    "X_test.loc[:, 'scannedLineItemsPerSecond'] = np.log(X_test.loc[:, 'scannedLineItemsPerSecond'] + 1)\n",
    "X_test.loc[:, 'valuePerSecond'] = np.log(X_test.loc[:, 'valuePerSecond'] + 1)\n",
    "X_test.loc[:, 'lineItemVoidsPerPosition'] = np.log(X_test.loc[:, 'lineItemVoidsPerPosition'] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision over training dataset: 0.7327\n",
      "Precision over validation dataset: 0.7317\n",
      "Precision over test dataset: 0.7188\n",
      "Recall over training dataset: 0.9944\n",
      "Recall over validation dataset: 0.9951\n",
      "Recall over test dataset: 0.9943\n",
      "F1 score over training dataset: 0.8437\n",
      "F1 score over validation dataset: 0.8433\n",
      "F1 score over test dataset: 0.8344\n"
     ]
    }
   ],
   "source": [
    "selected_features = ['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemVoids', 'scansWithoutRegistration', 'totalItems']\n",
    "\n",
    "feature_cols = [col for col in selected_features]\n",
    "target_col = ['fraud']\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train[target_col].copy()\n",
    "X_validate = validate[feature_cols].copy()\n",
    "y_validate = validate[target_col].copy()\n",
    "X_test  = test[feature_cols].copy()\n",
    "y_test  = test[target_col].copy()\n",
    "\n",
    "LogR = LogisticRegression(random_state=42, class_weight='balanced', max_iter=2000) # for imbalanced learning\n",
    "LogR.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Calculate precision, recall and f1-score for the training dataset\n",
    "precision_train = precision_score(y_train, LogR.predict(X_train))\n",
    "recall_train = recall_score(y_train, LogR.predict(X_train))\n",
    "f1_score_train = f1_score(y_train, LogR.predict(X_train))\n",
    "\n",
    "# Calculate precision, recall and f1-score for the validation dataset\n",
    "precision_validate = precision_score(y_validate, LogR.predict(X_validate))\n",
    "recall_validate = recall_score(y_validate, LogR.predict(X_validate))\n",
    "f1_score_validate = f1_score(y_validate, LogR.predict(X_validate))\n",
    "\n",
    "# Calculate precision, recall and f1-score for the test dataset\n",
    "precision_test = precision_score(y_test, LogR.predict(X_test))\n",
    "recall_test = recall_score(y_test, LogR.predict(X_test))\n",
    "f1_score_test = f1_score(y_test, LogR.predict(X_test))\n",
    "\n",
    "print('Precision over training dataset: {:0.4f}'.format(precision_train))\n",
    "print('Precision over validation dataset: {:0.4f}'.format(precision_validate))\n",
    "print('Precision over test dataset: {:0.4f}'.format(precision_test))\n",
    "print('Recall over training dataset: {:0.4f}'.format(recall_train))\n",
    "print('Recall over validation dataset: {:0.4f}'.format(recall_validate))\n",
    "print('Recall over test dataset: {:0.4f}'.format(recall_test))\n",
    "print('F1 score over training dataset: {:0.4f}'.format(f1_score_train))\n",
    "print('F1 score over validation dataset: {:0.4f}'.format(f1_score_validate))\n",
    "print('F1 score over test dataset: {:0.4f}'.format(f1_score_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
